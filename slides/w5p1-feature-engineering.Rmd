---
title: "Feature engineering"
subtitle: "An overview of the {recipes} package and some PCA"
author: "Daniel Anderson & Joe Nese"
date: "Week 5, Class 1"
output:
  xaringan::moon_reader:
    css: ["default", "uo", "uo-fonts", "hygge", "custom.css"]
    lib_dir: libs
    nature:
      highlightStyle: atelier-dune-light
      highlightLines: true
      countIncrementalSlides: false
      beforeInit: "https://platform.twitter.com/widgets.js"
---

```{r setup, include = FALSE}
knitr::opts_chunk$set(fig.width = 13, 
                      message = FALSE, 
                      warning = FALSE,
                      echo = TRUE)

library(tidyverse)

update_geom_defaults('path', list(size = 3, color = "cornflowerblue"))
update_geom_defaults('point', list(size = 3, color = "gray60"))
theme_set(theme_minimal(base_size = 25))
```

# Agenda 
* Basics of recipes
  - Formulas & specifying roles

* Handling categorical data

* Normalization

* Filtering

* General modifications

* Transformations

* Missing data

* PCA

---

.center[
![](https://github.com/tidymodels/recipes/raw/master/man/figures/logo.png)
]

* Alternative package for creating a .b[design matrix] (i.e., alternative to `model.matrix`).

* More extensible than existing systems

* Has some increases in efficiency

* Ensures operations are conducted by fold

* Side benefit - really forces you (the analyst) to think each step through

---
# recipe basics

* Define a "recipe" or blueprint for feature engineering

* Iteratively apply this blueprint to each fold during training

* Carry that blueprint forward to the test data

---
# Getting started
.b[Feel free to follow along] .ital[.g[or not, either is fine]]

```{r load-data}
library(tidyverse)
library(tidymodels)
d <- read_csv(here::here("data","train.csv")) %>% 
  select(-classification)

splt <- initial_split(d)
train <- training(splt)
```

---
# Formula
* As we've seen, we start by applying a formula.  

```{r rmd}
rec <- recipe(score ~ ., train)
```

* Notice we use our training dataset, not the CV splits (which we actually haven't even created yet).

* The data is only used to get the column names

---
# Blueprint vs Prepped
```{r prep}
rec

prep(rec)
```

---
# A problem
* Our current formula specifies .ital[.r[everything]] that is not `score` to be a predictor. Is that reasonable?


--
.center[

![](https://external-content.duckduckgo.com/iu/?u=https%3A%2F%2Fmedia.tenor.com%2Fimages%2F76d32a23ea4709821d1779abaa9211ab%2Ftenor.gif&f=1&nofb=1)

]

--
### Why?

* We have numerous ID variables (among other problems)

---
# Update roles

```{r update-role}
rec <- recipe(score ~ ., train) %>% 
  update_role(contains("id"), ncessch, new_role = "id vars")
rec
```

---
# Encoding categorical data
* Most of the columns in our dataset are categorical. We can't enter them directly as predictors - they need to be dummy coded.

* The formula interface usually does this for us. {recipes} makes us declare this explicitly.

* Helper functions
  + `all_predictors()`, `all_outcomes()` `all_nominal()`, `all_numeric()`

---
# Dummy code

```{r dummy1}
rec <- recipe(score ~ ., train) %>% 
  update_role(contains("id"), ncessch, new_role = "id vars") %>% 
  step_dummy(all_nominal())
rec
```

---
# View the prepped version

```{r prep-rec-dummy, error = TRUE}
prep(rec)
```

---
# Filter
* Remove zero variance predictors

```{r rm-zero-var1}
rec <- recipe(score ~ ., train) %>% 
  update_role(contains("id"), ncessch, new_role = "id vars") %>% 
  step_zv(all_predictors()) %>% 
  step_dummy(all_nominal())
rec
```

---
# Try prepped version again

```{r prep-rec-zv-dummy1, error = TRUE}
prep(rec)
```


---
# Double check

```{r train-check-constants}
train %>% 
  count(lang_cd)

train %>% 
  count(calc_admn_cd)
```

---
# Apply the blueprint
* We're going to go deeper with this, but first, let's look at what this blueprint is doing.

.g[could also use `juice` in this case, but `bake` is more general]

```{r bake}
rec %>% 
  prep %>% 
  bake(train) %>% 
  print(n = 5)
```

---
# A problem
* Our date variable was read in as a string. Let's fix that. 

.b[Note]: We could do this inside or outside of the recipe, it doesn't really matter, but doing it as part of the recipe will make for easier transportability to the test dataset.

```{r fix-date}
rec <- recipe(score ~ ., train) %>% 
  step_mutate(tst_dt = lubridate::mdy_hms(tst_dt)) %>% #<<
  update_role(contains("id"), ncessch, new_role = "id vars") %>% 
  step_zv(all_predictors()) %>% 
  step_dummy(all_nominal())
```

---
```{r bake-new-split}
rec %>% 
  prep %>% 
  bake(train)
```

---
# Alternatives
* You're probably most familiar with dummy coding .b[but] there there are alternatives


--
* One-hot encoding
  + Essentially equivalent to dummy-coding, but does not leave a group out (no need for a reference group in many modeling applications)
  

--
* Integer encoding
  + Assign a unique integer to each level - common in NLP applications


--
* Leave them as is
  + Tree-based methods and other applications may work just as well without any encoding
  
---
# Other considerations
* What if you have 500 rows, and a categorical variable that has 127 levels?
  + Look at the frequency of each category
  + Consider collapsing categories with small $n$ using `step_other`
  + Number of categories to retain could be treated as a hyperparameter during training


---
# Near zero variance predictors
* Sometimes you have variables that are highly imbalanced or sparse

* These variables can make precise estimation difficult

* We can use `step_nzv` to remove these variables prior to analysis

* Near-zero variance predictors have each of the following characteristics:

  + Very few unique values
  + Frequency ratio for the most common value to the second most common value is large
  
---
# Default NZV arguments
The variables that get removed is controlled by two arguments:
* `freq_cut = 95/5`: frequency ratio described on previous slide
* `unique_cut = 10`: $n$ unique values / total number of samples ( $\times$ 100)

A NZV will be identified if it is .r[larger] than `freq_cut` and .b[smaller] than `unique_cut`.

Example:

A column has 1000 values, one value is `1` and 999 are `2`. The `freq_cut` would be $999/1 = 999$ (larger than the default, $95/5 = 19$), while the `unique_cut` would be $(2 / 1000) \times 100 = 0.2$ (less than the default, $10$).


---
# Order matters
The order of the steps matters. Sometimes a lot. For example

```{r ex-step-order1}
ex_d <- tibble(f = factor(c(rep("a", 1), 
                            rep("b", 5), 
                            rep("c", 2), 
                            rep("d", 2),
                            rep("e", 90))),
               score = rnorm(100))
ex_d %>% 
  count(f)
```

---
# NZV first
```{r nzv-first}
recipe(score ~ ., ex_d) %>% 
  step_nzv(all_predictors()) %>% 
  step_dummy(all_predictors(), one_hot = TRUE) %>% 
  prep() %>% 
  juice()
```

---
# NZV second

```{r nzv-second}
recipe(score ~ ., ex_d) %>% 
  step_dummy(all_predictors(), one_hot = TRUE) %>% 
  step_nzv(all_predictors()) %>% 
  prep() %>% 
  juice()
```

---
# Back to our real data
Let's add some new variables

### From ODE
.g[Could get data from NCES or others too, of course]
.r[You don't need to follow along here]

Link is cut off in the below, but it's [here](https://www.oregon.gov/ode/reports-and-data/students/Documents/fallmembershipreport_20192020.xlsx).

```{r add-nces-data}
tmpfile <- tempfile()
download.file(
  "https://www.oregon.gov/ode/reports-and-data/students/Documents/fallmembershipreport_20192020.xlsx",
  tmpfile
)
sheets <- readxl::excel_sheets(tmpfile)
ode_schools <- readxl::read_xlsx(tmpfile,
                                 sheet = sheets[4])
```

---
# Pull percentage variables
```{r ode-percentages}
ethnicities <- ode_schools %>% 
  select(attnd_schl_inst_id = `Attending School ID`,
         sch_name = `School Name`,
         contains("%")) %>% 
  janitor::clean_names()
names(ethnicities) <- gsub("x2019_20_percent", "p", names(ethnicities))
ethnicities
```

---
# Join
```{r join-schl-ethnicities, message = TRUE}
train <- left_join(train, ethnicities)
```

---
# Center scale
* It may make sense to center/scale these proportion variables
  + centering will reduce collinearity
  + scaling needed if regularizing 

```{r center-scale}
rec <- recipe(score ~ ., train) %>% 
  step_mutate(tst_dt = lubridate::mdy_hms(tst_dt)) %>% 
  update_role(contains("id"), ncessch, new_role = "id vars") %>% 
  step_zv(all_predictors()) %>% 
  step_center(#<<
    all_numeric(), 
    -all_outcomes(), 
    -has_role("id vars")
  ) %>% 
  step_scale(#<<
    all_numeric(), 
    -all_outcomes(), 
    -has_role("id vars")
  ) %>% 
  step_dummy(all_nominal())
```

---
# Prepped
.g[Note that enrolled grade has been centered/scaled]

```{r prep-center-scale}
prep(rec)
```




---
class: inverse center middle
# Missing data

---
# Missingness
* Notice we have a lot of missing data - every row of the data frame has at least one missing observation


--
* For some models, this is not a big deal - estimate on the available data (e.g., some CART models)


--
* For most, you'll need to handle it somehow:

  + Delete missing values (rows)
  + Encode missingess
  + Impute missingness
  
---
# Deletion
* Most straightforward, but  often dangerous
  + Is the missingness systematic? (leading to systematic biases in your predictions)
  
```{r rec-missingness}
rec <- recipe(score ~ ., train) %>% 
  step_naomit(all_predictors())

rec %>% 
  prep() %>% 
  bake(train)
```

---
# Encode missingness
* For categorical variables, you can .b[model] the missingness by recoding the missing values to an "unknown" category

* Note you may want to consider `step_novel` too for handling novel factor levels outside of the training data.

```{r step_unknown}
rec <- recipe(score ~ ., train) %>% 
  step_unknown(all_nominal()) %>% 
  step_novel(all_nominal())

rec %>% 
  prep() %>% 
  bake(train) %>% 
  select(id, lang_cd)
```


---
# Imputation
Alternatively, you can create a model .b[for] the missingness. 

--
* Essentially equivalent to what we're doing all term long


--
* Treat the variable you are imputing as the outcome
  + Build a model with all other variables predicting the observed values
  + Use the model to predict missingness

--

.caution[Caution!]

--
* This .bolder[.b[will not]] fix MNAR issues

---
# What models?
* Very simple

  + Mean/median/mode imputation w/`step_*impute()`
  
  + Lower bound imputation w/`step_lowerimpute`


--
* Slight step up in complexity

  + Time series rolling window imputation w/`step_rollimpute`
  
      - by default provides a median imputation
  

--
* Considerably more complicated

  + K-Nearest Neighbor imputation w/`step_knnimpute`
  
  + Bagged trees imputation w/`step_bagimpute`
  
---
# A few examples

```{r airquality}
head(airquality)
```


---
Rows 5/6 have been mean imputed for `Solar.R`
```{r mean-impute}
airquality_rec <- recipe(Ozone ~ ., data = airquality) %>% 
  step_meanimpute(all_predictors()) 

airquality_rec %>% 
  prep() %>% 
  bake(airquality)
```

---
Now they've been imputed using a $k$ nearest neighbor model
```{r knn-impute}
airquality_rec <- recipe(Ozone ~ ., data = airquality) %>% 
  step_knnimpute(all_predictors()) #<<

airquality_rec %>% 
  prep() %>% 
  bake(airquality)
```

---
And finally with a bagged tree model
```{r bag-impute}
airquality_rec <- recipe(Ozone ~ ., data = airquality) %>% 
  step_bagimpute(all_predictors()) #<<

airquality_rec %>% 
  prep() %>% 
  bake(airquality)
```

---
# Which works best?
* Empirical question - i.e., part of your model development process (could be considered a hyperparamter)

* Do you want to only impute for your predictors? Or outcomes too?

  + Probably depends on your model, but generally it's more important to have complete data on your predictor variables than your outcome variable(s).


--
.caution[Reminder]

* Missing data is a big topic, and even the more advanced methods .r[will not] fix MNAR data.


---
class: inverse center middle
# Transformations and other considerations


---
# An example

```{r seg-data}
data(segmentationData, package = "caret")
seg <- segmentationData %>% 
  filter(Case == "Train") %>% 
  select(EqSphereAreaCh1, PerimCh1, Class) %>% 
  setNames(c("PredictorA", "PredictorB", "Class")) %>% 
  mutate(Class = factor(ifelse(Class == "PS", "One", "Two"))) %>% 
  as_tibble()
seg
```

---
# Separation

```{r sep-seg-plot, fig.height = 6}
ggplot(seg, aes(PredictorA, PredictorB, color = Class)) + 
  geom_point(alpha = .5) + 
  scale_color_brewer(palette = "Accent") +
  labs(title = "Natural units")
```

---
# Inverse transformation

```{r seg-inverse, fig.height = 5}
seg %>% 
  mutate(inv_PredictorA = 1/PredictorA, 
         inv_PredictorB = 1/PredictorB) %>% 
ggplot(aes(inv_PredictorA, inv_PredictorB, color = Class)) + 
  geom_point(alpha = .5) + 
  scale_color_brewer(palette = "Accent") +
  labs(title = "Inverse scale")
```

---
# Univariate view

```{r predictora-univariate, echo = FALSE}
seg %>% 
  mutate(inv_PredictorB = 1/PredictorB) %>% 
  pivot_longer(ends_with("B"),
               names_to = "scale",
               values_to = "val") %>% 
ggplot(aes(val, fill = scale)) + 
  geom_histogram(color = "white") +
  facet_wrap(~scale, scales = "free") +
  scale_fill_brewer(palette = "Accent") +
  guides(fill = "none")
```

---
# More general transformation
### Box-Cox transformation
Originally developed as a transformation of the outcome - can help with predictor variables too.

$$
\begin{equation}
 x^* =
	\begin{cases}
  	\frac{x^\lambda-1}{\lambda}, & \text{if}\ \lambda \neq 0 \\
   	\log\left(x\right), & \text{if}\ \lambda = 0
	\end{cases}
\end{equation}
$$


--
### Objective

Estimate $\lambda$ for each  variable to be transformed


--
Technically only for positive values. Use Yeo-Johnson transformation for positive & negative data.

---
# Common $\lambda$ mappings

* $\color{#157CAE}{\lambda} = 1$: No tranformation
* $\color{#157CAE}{\lambda} = 0$: log tranformation
* $\color{#157CAE}{\lambda} = 0.5$: square root tranformation
* $\color{#157CAE}{\lambda} = -1$: inverse


--
### Box Cox transformations
```{r seg-box-cox}
bc <- recipe(Class ~ ., data = seg) %>% 
  step_BoxCox(all_predictors()) %>% 
  prep() 
```

---
class: inverse center middle

# Tidying recipes

---
# tidy
* Once you've created a recipe, you may want to *tidy* it to get more information about a specific step

* In our previous example, we might want to know what $\lambda$ values were used in the Box-Cox transformation

--
```{r tidy-rec}
tidy(bc)
```

This basically just lists the steps (in this case there's only one). To get the information about the step, we have to specify which number we want to know more about.

---
# Box-Cox Models

```{r bc-tidy}
tidy(bc, n = 1)
```

We can see that the $\lambda$ values used was were very close to -1 for each variable, which is close to an inverse transformation.

---
# Backing up a bit
How do we estimate $\lambda$?


--
Complicated mathy stuff. But conceptually - find the value the minimizes the difference between the transformed values a theoretical normal distribution

---
# Example
```{r compute-lambdas}
lambdas <- c(-1, -0.5, 0, 0.5, 1)
names(lambdas) <- lambdas

lambda_transforms <- map_df(lambdas, ~ {
  if(.x == 0) {
    log(seg$PredictorB)
  } else {
   (seg$PredictorB^.x - 1) / .x 
  }
})

lambda_d <- seg %>% 
  select(raw = PredictorB) %>% 
  bind_cols(lambda_transforms)

head(lambda_d)
```

---
# Move to long

```{r pivot_lambdas_long}
lambda_d %>% 
  pivot_longer(-raw)
```

---
# Compare to theoretical quantiles

```{r plot-lambdas-echo, eval = FALSE}
lambda_d %>% 
  pivot_longer(-raw) %>% 
  ggplot(aes(sample = value)) +
  geom_qq_line() +
  stat_qq(aes(color = name)) +
  facet_wrap(~name, scales = "free_y")
```

---

```{r plot-lambdas-eval, echo = FALSE, fig.height = 9}
lambda_d %>% 
  pivot_longer(-raw) %>% 
  mutate(name = factor(name, 
                       levels = as.character(c(-1, -0.5, 0, 0.5, 1)))) %>% 
  ggplot(aes(sample = value)) +
  geom_qq_line() +
  stat_qq(aes(color = name)) +
  facet_wrap(~name, scales = "free_y") +
  labs(title = "Different lambda transformations",
       y = "Transformed value",
       x = "Theoretical Quantile")
```


---
## More complicated transformations
* Nonlinear transformations may help improve performance

  + Polynomials w/`step_poly`

      - Note, these are orthogonal polynomials by default 

  + Natural- or B-spline basis functions w/`step_ns` or `step_bs`
  
      - If you're interested in splines, or more generally, GAMs, I highly recommend [Noam Ross's free course](https://noamross.github.io/gams-in-r-course/) to get you started.


---
# Quick example
```{r plot-raw, fig.height = 6}
airquality <- airquality %>% 
  mutate(date = lubridate::make_date(month = Month, day = Day))

ggplot(airquality, aes(date, Temp)) +
  geom_point(color = "gray70")
```


---
# Natural spline basis expansion

```{r basis-expansion}
spline_rec <- recipe(Temp ~ ., airquality) %>%
  step_mutate(date = as.numeric(date)) %>% 
  step_ns(date) 

spline_d <- spline_rec %>% 
  prep() %>% 
  juice()
spline_d
```

---
# Fit model & make prediction

```{r spline-fit}
fit <- lm(Temp ~ date_ns_1 + date_ns_2, data = spline_d)
spline_pred <- spline_d %>% 
  mutate(spline_pred = predict(fit, newdata = spline_d)) 

spline_pred
```

---
# Plot predictions

```{r plot-preds, fig.height = 5.5}
spline_pred %>% 
  mutate(date = lubridate::make_date(month = Month, day = Day)) %>% 
  ggplot(aes(date, Temp)) +
  geom_point(color = "gray70") +
  geom_line(aes(y = spline_pred),
            color = "#4f8dde")
```

---
# Increase wiggliness
### Increase the degrees of freedom

```{r basis-expansion2}
spline_rec2 <- recipe(Temp ~ date, airquality) %>%
  step_mutate(date = as.numeric(date)) %>% 
  step_ns(date, deg_free = 7) 

spline_d2 <- spline_rec2 %>% 
  prep() %>% 
  juice()
names(spline_d2)
```

---
# Fit new model

```{r spline-fit2}
fit2 <- lm(Temp ~ ., data = spline_d2)
spline_pred2 <- spline_d2 %>% 
  mutate(spline_pred = predict(fit2, newdata = spline_d2),
         date = airquality$date) 
```

---
# Plot new predictions

```{r plot-preds2, fig.height = 5.5}
spline_pred2 %>% 
  ggplot(aes(date, Temp)) +
  geom_point(color = "gray70") +
  geom_line(aes(y = spline_pred),
            color = "#4f8dde")
```

---
# One more time
### Just for fun

```{r last-spline-code}
spline_rec3 <- recipe(Temp ~ date, airquality) %>%
  step_mutate(date = as.numeric(date)) %>% 
  step_ns(date, deg_free = 20) 

spline_d3 <- spline_rec3 %>% 
  prep() %>% 
  juice()

fit3 <- lm(Temp ~ ., data = spline_d3)
spline_pred3 <- spline_d3 %>% 
  mutate(spline_pred = predict(fit3, newdata = spline_d3),
         date = airquality$date) 
```

---
```{r last-spline-plot}
spline_pred3 %>% 
  ggplot(aes(date, Temp)) +
  geom_point(color = "gray70") +
  geom_line(aes(y = spline_pred),
            color = "#4f8dde")
```

---
# Finishing up on splines
* The default for `step_ns` is equivalent to `splines::ns(x, df = 2)`

  + Hyperparameter that can be tuned: see [here](https://tidymodels.github.io/tune/articles/getting_started.html) for an example.
  
  + You probably want to tune variables separately (otherwise the smooth is constrained to be equal)

* Could easily be a course on its own (and is)

* Really powerful and actually can be pretty interpretable

* Can be thought of as a feature engineering consideration (as it is through recipes) rather than a model fitting procedure alone

* Splines themselves are on a predictor-by-predictor basis, but can be extended to multivariate models with generalized additive models (GAMs)


---
class: inverse center middle
# Principal Components Analysis

---
# Collapsing data w/PCA
* For some models (e.g., linear regression) highly correlated variables can reduce predictive accuracy. Collapsing variables may help.

* Basically a way to take a whole bunch of variables and reduce them down to just a few, which carry most of the same information as the raw data

* Can help reduce overfitting, but if this is your primary concern, regularizatoin methods are probably better


--
.bolder[.b[Goal]]: Identify a small number of dimensions (components) that account for .r[X].b[%] of the variation captured by .ital[.bolder[all]] of the variables

---
# Recipe steps to check
* Data are [tidy](https://www.jstatsoft.org/article/view/v059i10) .g[Probs fix before recipe steps]

* No missing data

* All numeric data (so need to use dummy coding, etc)

* Numeric data should be standardized (centered & scaled)

---
# Get ready for PCA
Note, this is the same recipe we had before, except I've encoded and imputed missing data
```{r prep-pca}
rec <- recipe(score ~ ., train) %>% 
  step_mutate(tst_dt = lubridate::mdy_hms(tst_dt)) %>% 
  update_role(contains("id"), sch_name, ncessch, new_role = "id vars") %>% 
  step_zv(all_predictors()) %>% 
  step_unknown(all_nominal()) %>% #<<
  step_medianimpute(all_numeric(), -all_outcomes(), -has_role("id vars")) %>% #<<
  step_center(all_numeric(), -all_outcomes(), -has_role("id vars")) %>% 
  step_scale(all_numeric(), -all_outcomes(), -has_role("id vars")) %>% 
  step_dummy(all_nominal(), -has_role("id vars"))
```


---
# Retain 80% of the variance

```{r pca80}
rec80 <- rec %>% 
  step_pca(all_numeric(), -all_outcomes(), -has_role("id vars"), 
           threshold = .80)

rec80 %>% 
  prep() %>% 
  tidy()
```

---
# Which variable went to which?

```{r pca80-tidy}
rec80 %>% 
  prep() %>% 
  tidy(n = 8)
```

Note - we have too many features and too many components to produce many meaningful plots, but you could look at subsamples.

---
### How many PCAs to retain 95% of the variance?

```{r pca95}
rec %>% 
  step_pca(all_numeric(), -all_outcomes(), -has_role("id vars"), 
           threshold = .95) %>% 
  prep() %>% 
  juice() %>% 
  select(id, starts_with("PC"), score)
```

---
# One last note
This has obviously been a .b[.ital[very]] quick discussion of PCA. 

We're thinking of it primarily as a feature engineering approach.

Check out [Julia Silge's post](https://juliasilge.com/blog/best-hip-hop/) for more on PCA, continuing through a tidymodels view.

---
class: inverse center middle
# Wrapping up

---
# Feature engineering (FE)
* Almost endless possibilities

* Probably the most "art" part of ML

* Amazing FE and a simple model will regularly beat poor FE and a fancy model

* {recipes} is a great package to do a lot of the work for you


--
Remember - it creates a .b[blueprint]! This means, we can (and should) apply the blueprint (recipe) to each fold when we're using $k$-fold CV

---
# Full recipe
### 95% of variance in PCA

```{r final-rec}
rec <- recipe(score ~ ., train) %>% 
  step_mutate(tst_dt = lubridate::mdy_hms(tst_dt)) %>% 
  update_role(contains("id"), sch_name, ncessch, new_role = "id vars") %>% 
  step_zv(all_predictors()) %>% 
  step_unknown(all_nominal()) %>% 
  step_medianimpute(all_numeric(), -all_outcomes(), -has_role("id vars")) %>% 
  step_center(all_numeric(), -all_outcomes(), -has_role("id vars")) %>% 
  step_scale(all_numeric(), -all_outcomes(), -has_role("id vars")) %>% 
  step_dummy(all_nominal(), -has_role("id vars")) %>% 
  step_pca(all_numeric(), -all_outcomes(), -has_role("id vars"), 
           threshold = .95)

prepped_rec <- prep(rec)
```

---
# Apply in CV
* Note the transformations are being conducted .b[for each fold], which ensures there is no data leakage

```{r cv}
cv <- vfold_cv(train)
cv_baked <- cv %>% 
  mutate(baked = map(splits, ~bake(prepped_rec, .x)))
cv_baked
```

---
class: inverse 
# Next class
We'll review a bit of this, discuss any points of confusion, and get started on the lab.
